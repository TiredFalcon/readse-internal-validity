{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of survey answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import json\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "def load_raw_data():\n",
    "    raw_data_file = \"raw_data.json\"\n",
    "    with open(raw_data_file) as f:\n",
    "        data = json.load(f)\n",
    "        df = pd.json_normalize(data)\n",
    "\n",
    "    df['from.text'] = df['from.text'].astype('str')\n",
    "    df['to.text'] = df['to.text'].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert survey responses df with of [questionId, response, academicLevel]\n",
    "def to_qid_res_level(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop useless rows\n",
    "    df_data = df.drop(index=[0,1])\n",
    "    \n",
    "    # Extract academic status data (responseid -> Qlevel)\n",
    "    academic_status = df_data[['ResponseId', 'Qlevel']].dropna()\n",
    "    \n",
    "    # Remove useless columns and melt responses into one row per question-response pair\n",
    "    df_qid_res = df_data\\\n",
    "        .drop(axis = 'columns', columns = ['RecordedDate', 'Qlevel'])\\\n",
    "        .dropna(how = 'all')\\\n",
    "        .melt(id_vars=['ResponseId'],\n",
    "              var_name=\"qid\",\n",
    "              value_name=\"res\")\\\n",
    "        .dropna()\n",
    "    \n",
    "    # Add academic level column\n",
    "    df_qid_res_level = df_qid_res.merge(academic_status, on = 'ResponseId')\n",
    "    return df_qid_res_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert questions where paragraphs were reversed (their qid has \"-rev\" appended)\n",
    "# This is done by removing the \"-rev\" suffix from the id and inverting the likert response\n",
    "def to_unswapped(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Add \"was_rev\" column to indicate whether the question was reversed in the survey\n",
    "    df['was_rev'] = False\n",
    "    # Map to swap a Likert answer\n",
    "    swap_likert = {\n",
    "        \"Strongly agree\": \"Strongly disagree\",\n",
    "        \"Somewhat agree\": \"Somewhat disagree\",\n",
    "        \"Neither agree nor disagree\": \"Neither agree nor disagree\",\n",
    "        \"Somewhat disagree\": \"Somewhat agree\",\n",
    "        \"Strongly disagree\": \"Strongly agree\"\n",
    "    }\n",
    "    # Function to unswap row\n",
    "    def de_swap_qid_res(row):\n",
    "        if (row.qid.endswith('-rev')):\n",
    "            row.qid = row.qid[:-4]\n",
    "            row.res = swap_likert[row.res]\n",
    "            row.was_rev = True\n",
    "        else:\n",
    "            row.was_rev = False\n",
    "        return row\n",
    "    return df.apply(de_swap_qid_res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated responses\n",
    "# In an earlier version of the survey, some users could see both the normal and reversed\n",
    "# version of a question. We remove both to avoid problems.\n",
    "def remove_duplicated_answers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    id_cols = ['ResponseId', 'qid']\n",
    "    dup_filter = df.duplicated(id_cols, keep=False)\n",
    "    return df[~dup_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns from original data\n",
    "def add_measured_deltas_and_texts(df: pd.DataFrame, raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_to_add = [\n",
    "        '_id',\n",
    "        'freDelta', 'fkglDelta',\n",
    "        'from.text', 'to.text',\n",
    "        'from.readability.fleschReadingEase', 'from.readability.fleschKincaidGradeLevel',\n",
    "        'to.readability.fleschReadingEase', 'to.readability.fleschKincaidGradeLevel',\n",
    "    ]\n",
    "    raw_data_qid_deltas = raw_data[cols_to_add]\\\n",
    "        .rename(columns={\n",
    "        '_id': 'qid',\n",
    "        'from.readability.fleschReadingEase' : 'from.FRE',\n",
    "        'from.readability.fleschKincaidGradeLevel' : 'from.FKG',\n",
    "        'to.readability.fleschReadingEase' : 'to.FRE',\n",
    "        'to.readability.fleschKincaidGradeLevel' : 'to.FKG'\n",
    "    })\n",
    "    return df.merge(raw_data_qid_deltas, on = 'qid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all pairs of paragraphs we have the \"real\" readability delta stored, but for some pairs it increases and for some others it decreases.  \n",
    "This makes the data confusing, since it is impossible to know what the \"correct\" answer is for each pair of paragraphs.  \n",
    "\n",
    "In all cases the statement the survey asked to evaluate was *The first paragraph is more readable than the second*, which means that we implied a decrease in readability.  \n",
    "Therefore, we map all pairs of paragraphs (and survey responses) so that the \"real\" readability delta (in Flesch—Kincaid grade) is a decrease. This makes it so that \"Strongly agree\" and \"Somewhat agree\" are the expected survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all rows to be decreases in readability, so that the expected `res` is always\n",
    "# \"Strongly agree\" (or \"Somewhat agree\")\n",
    "# A row is considered a decrease in readability based on Flesch—Kincaid grade delta\n",
    "def to_all_decreases(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Map to swap a Likert answer\n",
    "    swap_likert = {\n",
    "        \"Strongly agree\": \"Strongly disagree\",\n",
    "        \"Somewhat agree\": \"Somewhat disagree\",\n",
    "        \"Neither agree nor disagree\": \"Neither agree nor disagree\",\n",
    "        \"Somewhat disagree\": \"Somewhat agree\",\n",
    "        \"Strongly disagree\": \"Strongly agree\"\n",
    "    }\n",
    "    # Function to swap a row to a decrease\n",
    "    def as_readability_decrease(row: pd.Series) -> pd.Series:\n",
    "        # If it's a readability increase swap it to a decrease\n",
    "        if (row['fkglDelta'] < 0):\n",
    "            row['from.text'], row['to.text'] = row['to.text'], row['from.text']\n",
    "            row['from.FRE'], row['to.FRE'] = row['to.FRE'], row['from.FRE']\n",
    "            row['from.FKG'], row['to.FKG'] = row['to.FKG'], row['from.FKG']\n",
    "            row['freDelta'] = - row['freDelta']\n",
    "            row['fkglDelta'] = - row['fkglDelta']\n",
    "            row['res'] = swap_likert[row['res']]\n",
    "            row['was_rev'] = not row['was_rev']\n",
    "        return row\n",
    "    return df.apply(as_readability_decrease, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process survey answers\n",
    "def process_survey_answers(survey_fname):\n",
    "    with open(survey_fname) as f:\n",
    "        df = pd.read_csv(f);\n",
    "    df_qid_res_level = to_qid_res_level(df)\n",
    "    df_unswapped = to_unswapped(df_qid_res_level)\n",
    "    df_no_dups = remove_duplicated_answers(df_unswapped)\n",
    "    raw_data_df = load_raw_data()\n",
    "    df_all = add_measured_deltas_and_texts(df_no_dups, raw_data_df)\n",
    "    df_final = to_all_decreases(df_all)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read survey data and write processed data to file\n",
    "def survey_processing() -> pd.DataFrame:\n",
    "    survey_datasets = ['survey_results/survey0.csv', 'survey_results/survey1.csv']\n",
    "    processed = [\n",
    "        process_survey_answers(raw_answers)\n",
    "        for raw_answers\n",
    "        in survey_datasets]\n",
    "    all_data: pd.DataFrame = pd.concat(processed)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all survey data\n",
    "outfname = 'survey_results_processed.csv'\n",
    "survey_processing().to_csv(outfname, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
